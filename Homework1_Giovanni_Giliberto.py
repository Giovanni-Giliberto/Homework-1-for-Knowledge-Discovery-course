# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SKLx0Kq4W27kGGFV9jOZ3jl2g35T9DTg
"""

import torch
import torchvision
from matplotlib import pyplot as plt
from tqdm.notebook import tqdm

!wget http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz
!tar -zxvf stl10_binary.tar.gz

root_dir = './'
torchvision.datasets.STL10(root=root_dir,download=True)

train_set = torchvision.datasets.STL10(root=root_dir, download=True, split="test")
test_set = torchvision.datasets.STL10(root=root_dir, download=True, split="train")

num_train = len(train_set)
num_test = len(test_set)
print(f"Num. training samples: {num_train}")
print(f"Num. test samples:     {num_test}")

# List of indexes on the training set
train_idx = list(range(num_train))


# List of indexes of the test set
test_idx = list(range(num_test))

# Shuffle the training set
import random

random.shuffle(train_idx)
for i in range(10):
  print(train_idx[i])

# Fraction of the original train set that is going to be used as validation set
val_frac=0.1
# Getting the number of validation set samples
num_val = int(num_train* val_frac)
num_train= num_train - num_val

# Splitting the train set into train and val (10% of train)
val_idx= train_idx[num_train:]
train_idx= train_idx[:num_train]

# Printing the number of samples belonging to train set and val set
print(f"{num_train} samples used for the train set")
print(f"{num_val}  samples used for the val set")

from torchvision import transforms

# Compose transformations
data_transform = transforms.Compose([
  transforms.RandomRotation(degrees=(0, 20)),
  transforms.RandomHorizontalFlip(p=0.5),
  transforms.RandomVerticalFlip(p=0.5),
  transforms.Resize(48),
  transforms.ToTensor(),
  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])
# Load SVHN dataset with transforms
train_set = torchvision.datasets.STL10(root=root_dir, split="test", download=True, transform=data_transform)
test_set = torchvision.datasets.STL10(root=root_dir, split="train", download=True, transform=data_transform)

# Split train_dataset into training and validation
from torch.utils.data import Subset

val_set = Subset(train_set, val_idx)
train_set = Subset(train_set, train_idx)

from torch.utils.data import DataLoader
train_loader = DataLoader(train_set, batch_size=64, num_workers=0, shuffle=True)
val_loader   = DataLoader(val_set,   batch_size=64, num_workers=0, shuffle=False)
test_loader  = DataLoader(test_set,  batch_size=64, num_workers=0, shuffle=False)

import torch.nn as nn

class SimpleCNN(nn.Module):

  #Constructor
  def __init__(self):
    # Call parent contructor
    super().__init__()
    self.conv_layer = nn.Sequential(
        # Layer 1
        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        # Layer 2
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        # Layer 3
        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2),
        # Layer 4
        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )

  # Forward
  def forward(self, x):
    #input is B x 1 x 28 x 28
    x = self.conv_layer(x)
    return x

model = SimpleCNN()
print(model)

# Get an element from the dataset
test_x, _ = train_set[0]

# Get the size of a sample
test_x.size()

test_x = test_x.unsqueeze(dim=0)
test_x.size()

output = model(test_x)
output.shape

out_features = output.size(1) * output.size(2) * output.size(3)
print(out_features)

class CNN(nn.Module):
  #Constructor
  def __init__(self):
    # Call parent contructor
    super().__init__()
    self.conv_layer = nn.Sequential(
        # Layer 1
        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.BatchNorm2d(64),
        # Layer 2
        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.BatchNorm2d(128),
        nn.MaxPool2d(kernel_size=2, stride=2),
        # Layer 3
        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.BatchNorm2d(256),
        nn.MaxPool2d(kernel_size=2, stride=2),
        # Layer 4
        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=0, stride=1),
        nn.ReLU(),
        nn.BatchNorm2d(512),
        nn.MaxPool2d(kernel_size=2, stride=2)
     
    )
    # Create fully-connected layers
    self.fc_layers = nn.Sequential(
        # a first FC layer
        nn.Linear(8192, 512),
        nn.ReLU(),
        # the final Classification Layer
        nn.Linear(512, 10)
    ) 

  # Forward
  def forward(self, x):
    x = self.conv_layer(x) 
    x = x.view(x.size(0), -1) 
    output = self.fc_layers(x) 
    return output

# Create the model
model = CNN()
output = model(test_x)
output.shape

dev = torch.device('cpu')
print(dev)

# Define an optimizier
import torch.optim as optim
optimizer = optim.SGD(model.parameters(), lr = 0.01)
# Define a loss 
criterion = nn.CrossEntropyLoss()

def train(net, loaders, optimizer, criterion, epochs=25, dev=torch.device('cpu')):
    try:
        net = net.to(dev)
        print(net)
        # Initialize history
        history_loss = {"train": [], "val": [], "test": []}
        history_accuracy = {"train": [], "val": [], "test": []}
        # Process each epoch
        for epoch in range(epochs):
            # Initialize epoch variables
            sum_loss = {"train": 0, "val": 0, "test": 0}
            sum_accuracy = {"train": 0, "val": 0, "test": 0}
            # Process each split
            for split in ["train", "val", "test"]:
                if split == "train":
                  net.train()
                else:
                  net.eval()
                # Process each batch
                for (input, labels) in tqdm(loaders[split],desc=split):
                    # Move to CUDA
                    input = input.to(dev)
                    labels = labels.to(dev)
                    # Reset gradients
                    optimizer.zero_grad()
                    # Compute output
                    pred = net(input)
                    loss = criterion(pred, labels)
                    # Update loss
                    sum_loss[split] += loss.item()
                    # Check parameter update
                    if split == "train":
                        # Compute gradients
                        loss.backward()
                        # Optimize
                        optimizer.step()
                    # Compute accuracy
                    _,pred_labels = pred.max(1)
                    batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)
                    # Update accuracy
                    sum_accuracy[split] += batch_accuracy
            # Compute epoch loss/accuracy
            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in ["train", "val", "test"]}
            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in ["train", "val", "test"]}
            # Update history
            for split in ["train", "val", "test"]:
                history_loss[split].append(epoch_loss[split])
                history_accuracy[split].append(epoch_accuracy[split])
            # Print info
            print(f"Epoch {epoch+1}:",
                  f"TrL={epoch_loss['train']:.4f},",
                  f"TrA={epoch_accuracy['train']:.4f},",
                  f"VL={epoch_loss['val']:.4f},",
                  f"VA={epoch_accuracy['val']:.4f},",
                  f"TeL={epoch_loss['test']:.4f},",
                  f"TeA={epoch_accuracy['test']:.4f},")
    except KeyboardInterrupt:
        print("Interrupted")
    finally:
        # Plot loss
        plt.title("Loss")
        for split in ["train", "val", "test"]:
            plt.plot(history_loss[split], label=split)
        plt.legend()
        plt.show()
        # Plot accuracy
        plt.title("Accuracy")
        for split in ["train", "val", "test"]:
            plt.plot(history_accuracy[split], label=split)
        plt.legend()
        plt.show()

# Define dictionary of loaders
loaders = {"train": train_loader,   
           "val": val_loader,
           "test": test_loader}

# Train model
train(model, loaders, optimizer, criterion, epochs=25, dev=dev)

#Confusion matrix
y_pred = []
y_true = []

import seaborn as sns
from sklearn.metrics import confusion_matrix 
import os 
import numpy as np 

# iterate over test data
for inputs, labels in test_loader:
  inputs, labels = inputs.cuda(), labels.cuda()
  output = model(inputs) # Feed Network
  output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()
  y_pred.extend(output) # Save Prediction
  
  labels = labels.data.cpu().numpy()
  y_true.extend(labels) # Save Truth

# constant for classes
classes = ["airplane",
"bird",
"car",
"cat",
"deer",
"dog",
"horse",
"monkey",
"ship",
"truck"]

# Build confusion matrix
cm = confusion_matrix(y_true, y_pred)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(17,10))
sns.heatmap(cmn, annot=True, xticklabels=classes, yticklabels=classes)
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False)